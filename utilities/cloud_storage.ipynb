{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "cloud_storage.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    }
  },
  "cells": [
    {
      "metadata": {
        "colab_type": "text",
        "id": "7Z2jcRKwUHqV"
      },
      "cell_type": "markdown",
      "source": [
        "This notebook provides recipes for loading and saving data from external sources."
      ]
    },
    {
      "metadata": {
        "id": "OtSLnroWg1MW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Local file system"
      ]
    },
    {
      "metadata": {
        "id": "Cn1hPHERg4pN",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Uploading files from your local file system\n",
        "\n",
        "`files.upload` returns a dictionary of the files which were uploaded.\n",
        "The dictionary is keyed by the file name, the value is the data which was uploaded."
      ]
    },
    {
      "metadata": {
        "id": "u7gSnpIfg75A",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "l6gnsQB3VPuj",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Drive\n",
        "\n",
        "You can access files in Drive in a number of ways, including:\n",
        "1. Using the [native REST API](https://developers.google.com/drive/v3/web/about-sdk);\n",
        "1. Using a wrapper around the API such as [PyDrive](https://gsuitedevs.github.io/PyDrive/docs/build/html/index.html); or\n",
        "1. Mounting your Google Drive in the runtime's virtual machine."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "u22w3BFiOveA"
      },
      "cell_type": "markdown",
      "source": [
        "## Mounting Google Drive locally\n",
        "\n",
        "The example below shows how to mount your Google Drive in your virtual machine using an authorization code, and shows a couple of ways to write & read files there. Once executed, observe the new file (`foo.txt`) is visible in https://drive.google.com/\n",
        "\n",
        "Note this only supports reading and writing files; to programmatically change sharing settings etc use one of the other options below."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "RWSJpsyKqHjH",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "S7c8WYyQdh5i"
      },
      "cell_type": "markdown",
      "source": [
        "# Google Cloud Storage (GCS)\n",
        "\n",
        "We'll start by authenticating to GCS and creating the service client."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "xM70QWdxeE7q",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import auth\n",
        "auth.authenticate_user()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "NAM6vyXAfVUj"
      },
      "cell_type": "markdown",
      "source": [
        "## Upload a file from Python to a GCS bucket\n",
        "\n",
        "\n",
        "\n",
        "We'll start by creating the sample file to be uploaded."
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "BCiCo3v9fwch"
      },
      "cell_type": "markdown",
      "source": [
        "Next, we'll upload the file using the `gsutil` command, which is included by default on Colab backends."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "VYC5CyAbAtU7",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# First, we need to set our project. Replace the assignment below\n",
        "# with your project ID.\n",
        "project_id = 'chatbotdemo-ai'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "TpnuFITI6Tzu",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "!gcloud config set project {project_id}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "Bcpvh_R_6jKB",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import uuid\n",
        "\n",
        "# Make a unique bucket to which we'll upload the file.\n",
        "# (GCS buckets are part of a single global namespace.)\n",
        "bucket_name = 'sample-bucket-' + str(uuid.uuid1())\n",
        "\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/mb\n",
        "!gsutil mb gs://{bucket_name}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "L5cMl7XV65be",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Copy the file to our new bucket.\n",
        "# Full reference: https://cloud.google.com/storage/docs/gsutil/commands/cp\n",
        "!gsutil cp trained_model.pkl gs://{bucket_name}/"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "0ENMqxq25szn"
      },
      "cell_type": "markdown",
      "source": [
        "### Using Python"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "YnN-iG9y56V-"
      },
      "cell_type": "markdown",
      "source": [
        "This section demonstrates how to upload files using the native Python API rather than `gsutil`.\n",
        "\n",
        "This snippet is based on [a larger example](https://github.com/GoogleCloudPlatform/storage-file-transfer-json-python/blob/master/chunked_transfer.py) with additional uses of the API."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YsXBVQqkArHD",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# The first step is to create a bucket in your cloud project.\n",
        "#\n",
        "# Replace the assignment below with your cloud project ID.\n",
        "#\n",
        "# For details on cloud projects, see:\n",
        "# https://cloud.google.com/resource-manager/docs/creating-managing-projects\n",
        "project_id = 'chatbotdemo-ai'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "YFVbF4cdhd9Y",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate to GCS.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Create the service client.\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "# Generate a random bucket name to which we'll upload the file.\n",
        "import uuid\n",
        "bucket_name = 'sample-bucket-' + str(uuid.uuid1())\n",
        "\n",
        "body = {\n",
        "  'name': bucket_name,\n",
        "  # For a full list of locations, see:\n",
        "  # https://cloud.google.com/storage/docs/bucket-locations\n",
        "  'location': 'us',\n",
        "}\n",
        "gcs_service.buckets().insert(project=project_id, body=body).execute()\n",
        "print('Done')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "ppkrR7p4mx_P"
      },
      "cell_type": "markdown",
      "source": [
        "**a. The cell below uploads the file from google drive to our newly created bucket.**"
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "cFAq-F2af5TJ",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('/content/gdrive/My Drive/trained_model.pkl', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "# media = MediaFileUpload('trained_model.pkl', \n",
        "#                         mimetype='text/plain',\n",
        "#                         resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='trained_model.pkl',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "n7EnV3QMXbDb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "**b. The cell below uploads the file from local to our newly created bucket.**\n"
      ]
    },
    {
      "metadata": {
        "id": "SP5GKqUOXbbL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from googleapiclient.http import MediaFileUpload\n",
        "\n",
        "media = MediaFileUpload('trained_model.pkl', \n",
        "                        mimetype='text/plain',\n",
        "                        resumable=True)\n",
        "\n",
        "request = gcs_service.objects().insert(bucket=bucket_name, \n",
        "                                       name='trained_model.pkl',\n",
        "                                       media_body=media)\n",
        "\n",
        "response = None\n",
        "while response is None:\n",
        "  # _ is a placeholder for a progress object that we ignore.\n",
        "  # (Our file is small, so we skip reporting progress.)\n",
        "  _, response = request.next_chunk()\n",
        "\n",
        "print('Upload complete')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "cyqTizOtnZEf"
      },
      "cell_type": "markdown",
      "source": [
        "Once the upload has finished, the data will appear in the cloud console storage browser for your project:\n",
        "\n",
        "https://console.cloud.google.com/storage/browser?project=YOUR_PROJECT_ID_HERE"
      ]
    },
    {
      "metadata": {
        "id": "58pPupFFnHRs",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Downloading a file from GCS to Python\n",
        "\n",
        "Next, we'll download the file we just uploaded in the example above. It's as simple as reversing the order in the `gsutil cp` command.*italicized text*"
      ]
    },
    {
      "metadata": {
        "id": "ZpMg-P5xnKj2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Download the file.\n",
        "!gsutil cp gs://{bucket_name}/trained_model.pkl /tmp/trained_model.pkl\n",
        "  \n",
        "# Print the result to make sure the transfer worked.\n",
        "!cat /tmp/trained_model.pkl"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "s6nDq8Nk7aPN"
      },
      "cell_type": "markdown",
      "source": [
        "#### Using Python"
      ]
    },
    {
      "metadata": {
        "colab_type": "text",
        "id": "P6aWjfTv7bit"
      },
      "cell_type": "markdown",
      "source": [
        "We repeat the download example above using the native Python API."
      ]
    },
    {
      "metadata": {
        "colab_type": "code",
        "id": "z1_FuDjAozF1",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Authenticate to GCS.\n",
        "from google.colab import auth\n",
        "auth.authenticate_user()\n",
        "\n",
        "# Create the service client.\n",
        "from googleapiclient.discovery import build\n",
        "gcs_service = build('storage', 'v1')\n",
        "\n",
        "from apiclient.http import MediaIoBaseDownload\n",
        "\n",
        "with open('/content/gdrive/My Drive/trained_model.pkl', 'wb') as f:\n",
        "  request = gcs_service.objects().get_media(bucket=bucket_name,\n",
        "                                            object='trained_model.pkl')\n",
        "  media = MediaIoBaseDownload(f, request)\n",
        "\n",
        "  done = False\n",
        "  while not done:\n",
        "    # _ is a placeholder for a progress object that we ignore.\n",
        "    # (Our file is small, so we skip reporting progress.)\n",
        "    _, done = media.next_chunk()\n",
        "\n",
        "print('Download complete')"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}