{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "heart-disease-risk-assessment.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "private_outputs": true,
      "collapsed_sections": [
        "bQnUqzBnMDWr"
      ],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vbosstech/disease-diagnostic-from-symptoms/blob/master/heart_disease_risk_assessment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "metadata": {
        "id": "XD_OrcJHMDSH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Predicting Heart Disease using UCI-repository Data-Set\n",
        "\n",
        "## In lieu of using the available processed data with 14 attributes in CSV format, I am starting with the complete dataset of 76 attributes. \n",
        "\n",
        "   ### Task 1: Put data in dataframe and remove irrelevant columns. \n",
        "   ### Task 2: Feature Selection/Addressing missing values\n",
        "   ### Task 3: Explore data - see which fetaures are relevant. \n",
        "   ### Task 4: Check for imbalanced class set.\n",
        "   ### Task 5: Exploring models \n",
        "   ### Task 6: Hyperparameter optimization - fine tuning the selected model.\n",
        "   ### Task 7: Test the selected model\n",
        "   ### Task 8: Assess the selected model"
      ]
    },
    {
      "metadata": {
        "id": "aMlqnilnYAU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "# drive.mount('/content/gdrive')\n",
        "drive.mount(\"/content/gdrive\", force_remount=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zl5gv2kwMDSJ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### Task 1. Getting data together"
      ]
    },
    {
      "metadata": {
        "id": "ZEwIoco_MDSL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import io\n",
        "import requests\n",
        "import pandas as pd\n",
        "import numpy as np \n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "%matplotlib inline\n",
        "\n",
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/hungarian.data'\n",
        "\n",
        "df = pd.read_csv(url)\n",
        "df.head(10) #This is not in the right format!"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zOaZXu8qMDSS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "r = requests.get(url)\n",
        "#if r.status_code != requests.codes.ok:\n",
        "   # r.raise_for_status()\n",
        "\n",
        "data = r.text.replace('\\n', ' ').replace(' name ', ' name\\n')\n",
        "\n",
        "hungary = pd.read_table(io.StringIO(data), sep='\\s+', header=None)\n",
        "print(hungary)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pN_BoWr0MDSW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/long-beach-va.data'\n",
        "r = requests.get(url)\n",
        "#if r.status_code != requests.codes.ok:\n",
        "   # r.raise_for_status()\n",
        "\n",
        "data1 = r.text.replace('\\n', ' ').replace(' name ', ' name\\n')\n",
        "\n",
        "lb = pd.read_table(io.StringIO(data1), sep='\\s+', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VEFON8gTMDSa",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/heart-disease/switzerland.data'\n",
        "r = requests.get(url)\n",
        "#if r.status_code != requests.codes.ok:\n",
        "   # r.raise_for_status()\n",
        "\n",
        "data2 = r.text.replace('\\n', ' ').replace(' name ', ' name\\n')\n",
        "\n",
        "switz = pd.read_table(io.StringIO(data2), sep='\\s+', header=None)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zyqAPBsrMDSc",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "frames = [hungary, lb, switz] #Now I want to merge all 3 dataframes and then I will label the columns\n",
        "df = pd.concat(frames)\n",
        "df.head(5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "r-HtOKv0MDSh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2. Feature Selection"
      ]
    },
    {
      "metadata": {
        "id": "-oyqbJDDMDSi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "col_list = [2,3,8,9,11,14,15,16,17,18,31,32,33,34,37,39,40,43,50,57] \n",
        "#Selecting features - for now i'm elminating blank columns (there are a lot of blank columns here)\n",
        "            \n",
        "hungary=hungary[col_list]\n",
        "lb = lb[col_list]\n",
        "switz=switz[col_list]\n",
        "\n",
        "frames = [hungary, lb, switz]\n",
        "df = pd.concat(frames)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CsA6P5v9MDSm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.columns=['age','sex','cp_type','rest_bp','chol','yrs_smoke','fbs','hist_dm','hist_cad','rest_ecg','max_hr','rest_hr',\n",
        "                'ex_bp1','ex_bp2','exang','oldpeak','slope','ca','thal','outcome']\n",
        "#These are the new column labels"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jzOSkoXpMDSr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.head(5) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JbzdaqaQMDSz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Looking for Null values or missing values"
      ]
    },
    {
      "metadata": {
        "id": "AtdHWIjCMDS0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.info() #So far everything is not null, but I'll come back to this as some of the negative numbers above are concerning"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "p8USnQe8MDS4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "max_hr_neg = df[df.max_hr <= 0] \n",
        "print(max_hr_neg) \n",
        "#Nothing is null so maybe some are negative? #Yup, there are a lot of negative values which don't make\n",
        "#sense in this context as you can't have a negative heart rate or bp. I will explore/address this later on."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "5SdhAEa_MDS-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 3. Exploring the data"
      ]
    },
    {
      "metadata": {
        "collapsed": false,
        "id": "dbXl7bHHMDS_",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Are age and sex related to heart disease?"
      ]
    },
    {
      "metadata": {
        "id": "8CML5jtIMDTA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "\n",
        "ax1 = fig.add_subplot(211)\n",
        "ax1.scatter(df.age,df.outcome)\n",
        "plt.xlabel('age')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Does Age predict outcome?')\n",
        "\n",
        "ax3 = fig.add_subplot(212)\n",
        "ax3.scatter(df.max_hr,df.outcome)\n",
        "plt.xlabel('max HR')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Does max_HR relate to outcome?')\n",
        "fig.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VSmGMLZeMDTE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Hard to see much with the tradition plot, adding some jitter\n",
        "import seaborn as sns\n",
        "fig = plt.figure(figsize=(20,16))\n",
        "\n",
        "ax1 = fig.add_subplot(331)\n",
        "a1 = sns.stripplot(df.yrs_smoke,df.outcome, jitter=True)\n",
        "plt.xlabel('yrs_smoke')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Yrs_smoke vs outcome')\n",
        "\n",
        "ax2 = fig.add_subplot(332)\n",
        "a2 = sns.stripplot(df.hist_dm,df.outcome, jitter=True)\n",
        "plt.xlabel('hist_dm')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('History of diabetes v outcome')\n",
        "\n",
        "ax3 = fig.add_subplot(333)\n",
        "a3 = sns.stripplot(df.hist_cad,df.outcome, jitter=True)\n",
        "plt.xlabel('hist_cad')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('History of heart disease v outcome')\n",
        "\n",
        "ax4 = fig.add_subplot(334)\n",
        "a4 = sns.stripplot(df.slope,df.outcome, jitter=True)\n",
        "plt.xlabel('slope')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Slope of peak exercise v outcome')\n",
        "fig.tight_layout()\n",
        "\n",
        "ax5 = fig.add_subplot(335)\n",
        "a5 = sns.stripplot(df.ca,df.outcome, jitter=True)\n",
        "plt.xlabel('ca')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Malformed arteries v outcome')\n",
        "fig.tight_layout()\n",
        "\n",
        "ax6 = fig.add_subplot(336)\n",
        "a6 = sns.stripplot(df.thal,df.outcome, jitter=True)\n",
        "plt.xlabel('thal')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Blood disorders v outcome')\n",
        "fig.tight_layout()\n",
        "\n",
        "ax7 = fig.add_subplot(337)\n",
        "a7 = sns.stripplot(df.sex,df.outcome, jitter=True)\n",
        "plt.xlabel('sex')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Sex v outcome')\n",
        "fig.tight_layout()\n",
        "\n",
        "ax8 = fig.add_subplot(338)\n",
        "a8 = sns.stripplot(df.cp_type,df.outcome, jitter=True)\n",
        "plt.xlabel('CP_type')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('CP_type v outcome')\n",
        "fig.tight_layout()\n",
        "\n",
        "ax9 = fig.add_subplot(339)\n",
        "a9 = sns.stripplot(df.ca,df.outcome, jitter=True)\n",
        "plt.xlabel('Ca')\n",
        "plt.ylabel('outcome')\n",
        "plt.title('Ca v outcome')\n",
        "fig.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "rHHIGIFxMDTI",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Plotting one-by-one seems tedious. Lets try something different -\n",
        "# from pandas.tools.plotting import scatter_matrix\n",
        "from pandas.plotting import scatter_matrix\n",
        "plot = scatter_matrix(df, figsize=(40, 40))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wq9dtOjEMDTM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now I'm trying to get a feel for the negative values and what the data looks like if I exclude the negative values\n",
        "\n",
        "fig = plt.figure(figsize=(6,4))\n",
        "\n",
        "ax1 = fig.add_subplot(221)\n",
        "plt.hist(df.max_hr) # Need to find and drop these 0s \n",
        "plt.title('Max HR - frequency distribution')\n",
        "plt.ylabel('HR (beats/min)')\n",
        "\n",
        "ax2 = fig.add_subplot(222)\n",
        "plt.hist(df.rest_hr) # Need to find and drop these 0s \n",
        "plt.title('Rest HR - frequency distribution')\n",
        "plt.ylabel('HR (beats/min)')\n",
        "\n",
        "ax3 = fig.add_subplot(223)\n",
        "plt.hist(df.age) #Since I imported SNS above, everything now defaults to seaborn style? how do i fix this?\n",
        "plt.title('Age - frequency distribution')\n",
        "plt.ylabel('age')\n",
        "\n",
        "ax4 = fig.add_subplot(224)\n",
        "max_hr_pos = df[df.max_hr >= 0] #We don't want to eliminate the whole rows for the negative values, we just want to replace with Nan\n",
        "plt.hist(max_hr_pos.max_hr)\n",
        "plt.title('New Histogram of max_HR')\n",
        "plt.ylabel('HR (beats/min)')\n",
        "\n",
        "fig.tight_layout()\n",
        "\n",
        "# Something funny is going on with the HRs - why are there negative numbers? Going to explore this\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EJCbuqJCMDTS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rest_hr_pos = df[df.rest_hr >= 0] #Again just filtering out the negative ones for graphing purposes"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OJVsFdHvMDTW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#I'm going to divide the data by outcome group \n",
        "#I'm just going to explore if there are obvious differences in these features between the groups. \n",
        "chd_pos = df[df.outcome >= 1] \n",
        "chd_neg = df[df.outcome == 0]\n",
        "#Going to look at cholesterol and max HR first\n",
        "fig = plt.figure(figsize =(12,8))\n",
        "ax = fig.add_subplot(221)\n",
        "n=4\n",
        "ind1=np.arange(pd.value_counts(chd_neg['outcome']))\n",
        "y = chd_pos['chol'] #, chd_neg['chol']]\n",
        "x = chd_pos.outcome\n",
        "ax.scatter(y, x)\n",
        "ax.scatter(chd_neg['chol'], chd_neg['outcome'], cmap='gray')\n",
        "ax.set_ylim(-.2,4.2)\n",
        "ax.set_title('Spread of Cholesterol levels in those with and without heart disease')\n",
        "yTickMarks = ['', 'Heart Disease NO', 'Heart Disease 1', 'Heart Disease 2', 'Heart Disease 3', 'Heart Disease 4']\n",
        "ax.set_yticklabels(yTickMarks)\n",
        "\n",
        "\n",
        "ax1 = fig.add_subplot(222)\n",
        "n=4\n",
        "ind1=np.arange(pd.value_counts(chd_neg['outcome']))\n",
        "y = chd_pos['max_hr'] #, chd_neg['chol']]\n",
        "x = chd_pos.outcome\n",
        "ax1.scatter(y, x)\n",
        "ax1.scatter(chd_neg['max_hr'], chd_neg['outcome'], cmap='gray')\n",
        "ax1.set_ylim(-.2,4.2)\n",
        "ax1.set_title('Spread of Max Heart Rate in those with and without heart disease')\n",
        "yTickMarks = ['', 'Heart Disease NO', 'Heart Disease 1', 'Heart Disease 2', 'Heart Disease 3', 'Heart Disease 4']\n",
        "ax1.set_yticklabels(yTickMarks)\n",
        "\n",
        "fig.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qpl_GSfyMDTb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Now I'm exploring some of those columns that seemed to have all negative #s \n",
        "#like yrs_smoke, hist_dm, hist_cad, slope, ca, and thal\n",
        "#I'm going to explore some of this columns with -9s to see if they take up the entire column. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X5Hahd2NMDTd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 2 - revisited) Looking for Null values or missing values \n",
        "### Now i've determined there are no null values but there are a lot of \"-9\"s in lieu of null values. "
      ]
    },
    {
      "metadata": {
        "id": "i2khMT1SMDTe",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#I'm going to try a few different ways of feature/selection missing values to see what impact it has on the data\n",
        "\n",
        "## option 1 - regular data, -9s and 0s present, all data included \n",
        "## option 2 - thresholded 50%; discrete variables: change to ohe coded, impute continuous variables\n",
        "## option 3 - thresholded 50; discrete variables: keep as label coded, impute continuous variables\n",
        "## option 4 - normalized data - some classifiers like regression and svm require normalized data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ztpgIn8sMDTh",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Option 1:  Regular data - 0s and -9s included instead of NaNs"
      ]
    },
    {
      "metadata": {
        "id": "iSB8zI3WMDTi",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features = df.iloc[:, :-1]\n",
        "target = df.outcome"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0gjfldBKMDTk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Option 2: - thresholded 50%; discrete variables: changed to ohe coding, impute contunous variables"
      ]
    },
    {
      "metadata": {
        "id": "ntIlMNfYMDTm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collist1=['age','rest_bp','chol','yrs_smoke','max_hr','rest_hr','ex_bp1','ex_bp2'] #list of not categorical features where -9s and 0s need to be turned into NaNs\n",
        "collist2 = ['sex','cp_type','fbs','hist_dm','hist_cad','rest_ecg','exang','slope','ca','thal','oldpeak']\n",
        "#list of not categorical and not catergorical features where -9s only need to be turned into NaNs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zshcFXL_MDTp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_notcat = df[collist1]\n",
        "df_notcat = df_notcat[df_notcat > 0] #Replacing the -9s and 0s with NaNs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "IYA9HdIhMDTu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_cat = df[collist2]\n",
        "df_cat = df_cat[df_cat > -9] #Replacing the -9s with NaNs"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Tv8uDqiAMDTx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "frames = [df_notcat, df_cat]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "9SzYmb5zMDT2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_hasnull = pd.concat(frames, axis=1)\n",
        "df_hasnull.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dt67xiBvMDT9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (df_hasnull.isnull().sum())\n",
        "print (len(df_hasnull)) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5s9JU0aKMDUA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_hasnull = df_hasnull.dropna(axis=1,thresh=308)\n",
        "df_hasnull.info() \n",
        "#Excluding columns with greater than 50% missing values. \n",
        "#Even if we impute these values, it won't buy us much."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "SHEjOz2IMDUE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cont_col_missing = ['rest_bp','chol','max_hr','rest_hr','ex_bp1','ex_bp2','oldpeak']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kEDfSLOiMDUH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#I will now go through the columns of missing values and see if there is any relation between the column with missing values\n",
        "# and any other columns \n",
        "def plot_features(x, title):\n",
        "    plt.figure(figsize=(10,14));\n",
        "    i = 0\n",
        "    for col in cont_col_missing:\n",
        "        i += 1\n",
        "        plt.subplot(7,2,i)\n",
        "        plt.scatter(df_hasnull[col], df_hasnull[x])\n",
        "        plt.title(title % (col, x))\n",
        "        plt.tight_layout()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VU0-iS8EMDUJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for x in cont_col_missing:\n",
        "    plot_features(x, 'Relationship of %s and %s')\n",
        "#columns with missing valuesplot_features('rest_bp', 'Relationship of %s and rest bp')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ks3FBkFZMDUO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Looking for possible linear relationships from graphs above\n",
        "\n",
        "# !pip3 install --upgrade -q statsmodels\n",
        "\n",
        "# import statsmodels.formula.api as smf\n",
        "# import statsmodels.api as sm\n",
        "\n",
        "## TODO\n",
        "# from pandas.stats.api import ols\n",
        "# res = ols(y=df_hasnull.ex_bp2, x=df_hasnull.ex_bp1).fit()\n",
        "# res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hZBg-jv7MDUS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## TODO\n",
        "# from pandas.stats.api import ols\n",
        "# res = ols(y=df_hasnull.rest_hr, x=df_hasnull.max_hr)\n",
        "# res"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "maG19GmlMDUV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_feat = ['sex','cp_type','fbs', 'rest_ecg', 'exang', 'slope']"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ag_KNc1_MDUY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for col in df_hasnull:\n",
        "    if col not in cat_feat:\n",
        "        df_hasnull.loc[:,col].fillna(df_hasnull[col].mean(), inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kVuckSiyMDUb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_hasnull_ohe = df_hasnull.copy()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "scrolled": true,
        "id": "dfMAlv3kMDUh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_ohe = df_hasnull_ohe.fillna(0)\n",
        "df_ohe = pd.get_dummies(df_ohe, columns=cat_feat, dummy_na=True)\n",
        "df_ohe.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zKlR6bqAMDUv",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_ohe = df_ohe"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "VOk94N-FMDUy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Option 3: thresholded 50; discrete variables: label coding, impute contunous variables"
      ]
    },
    {
      "metadata": {
        "id": "3xnkcOlAMDUz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Typically, random forest methods and other methods encourage two ways of handling missing values if we don't know\n",
        "#anything about the data: The first step is to look for relationships with the data - can one variable predict another? \n",
        "#a) drop data points with missing values (not recommended); \n",
        "#b) fill in missing values with the median (for numerical values) or mode (for categorical values). "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "PTr3Cc5FMDU2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_hasnull_label = df_hasnull.copy() #Already thresholded and continous variables have been imputed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kehorQtlMDU6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "cat_col_missing = ['fbs','rest_ecg','exang','slope'] #list of the categorical features with missing values "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LrW6d5EsMDU8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for col in cat_col_missing:\n",
        "        df_hasnull_label.loc[:,col].fillna(df_hasnull_label[col].mode().iloc[0], inplace=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eiaWQp1cMDU9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_label = df_hasnull_label"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "pMl9Y6lmMDVC",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "##### Option 4: normalized data - some classifiers like regression and svm require normalized data"
      ]
    },
    {
      "metadata": {
        "id": "bpx2cFuWMDVD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collist1=['age','rest_bp','chol','max_hr','rest_hr',\n",
        "                'ex_bp1','ex_bp2','oldpeak']\n",
        "df_norm1 = df_hasnull_label[collist1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "i_H_iujXMDVF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "collist2 = ['sex','cp_type','fbs','rest_ecg','exang','slope']\n",
        "df_categorical = df_hasnull_label[collist2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vz06rX0ZMDVK",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_norm2 = (df_norm1 - df_norm1.mean()) /  (df_norm1.std())\n",
        "df_norm2.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zmT-vbBYMDVN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_categorical.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Z-bCt4kGMDVT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "normdata = [df_categorical, df_norm2]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZAzhrJNlMDVW",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df_norm = pd.concat(normdata, axis=1)\n",
        "df_norm.head()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "M2FqxsXcMDVZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_norm = df_norm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "6WrG5KD2MDVd",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Further exploration - what features are important for distinguishing heart disease from no heart disease?"
      ]
    },
    {
      "metadata": {
        "id": "LUFJG40oMDVf",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#I'm just going to turn this into a binary problem where 0 is no heart disease and 1 means \n",
        "# the patient developed heart disease (irrespective of the type of heart disease)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "fB1-6rYlMDVh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "target_binary = target.replace(to_replace=[2,3,4], value=1,)\n",
        "target_binary.value_counts()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ooDGI8jtMDVl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Q09ObglbMDVn",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#I'd like to know the important features that distinguish heart disease from no heart disease. I don't care about accuracy\n",
        "#so much here.\n",
        "dtree = DecisionTreeClassifier(max_depth=3)\n",
        "log = LogisticRegression(class_weight='balanced')\n",
        "from sklearn.cross_validation import train_test_split \n",
        "from sklearn.cross_validation import cross_val_score "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "80NBKq7MMDVp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_ohe\n",
        "y = target_binary\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "JObxwXz6MDVq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = dtree.fit(X_train, y_train)\n",
        "cross_val_score(clf, X_train, y_train, cv=5)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "WHi_gjO6MDVx",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hiMmeLIwMDV0",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "feature_cols = features_ohe.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Cnk-QOU-MDV2",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "len(X_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f0AOcs6MMDV4",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import export_graphviz\n",
        "with open(\"/content/gdrive/My Drive/machine-learning/disease-diagnostic-from-symptoms/dot-files/tree.dot\", 'wb') as f:\n",
        "    f = export_graphviz(clf, out_file=f, feature_names=feature_cols)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "LKBhsQjgMDV5",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "<img src=\"tree2.png\">"
      ]
    },
    {
      "metadata": {
        "id": "s9SAVY-DMDV6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 4. Check for imbalanced class set."
      ]
    },
    {
      "metadata": {
        "id": "E_wf42TAMDV7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "df.outcome.value_counts(normalize=True)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "N2J5egwgMDV9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 5. Exploring models "
      ]
    },
    {
      "metadata": {
        "id": "fHw0lU2FMDV-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.cross_validation import train_test_split \n",
        "from sklearn.cross_validation import cross_val_score \n",
        "from sklearn.metrics import (auc, roc_curve, roc_auc_score,\n",
        "                             accuracy_score, precision_score,\n",
        "                             recall_score, f1_score, )\n",
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.multiclass import OneVsRestClassifier"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "go7BHYB1MDWA",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "logistic = LogisticRegression(C=1, multi_class='ovr', solver='lbfgs', class_weight='balanced')\n",
        "treeclf = DecisionTreeClassifier(class_weight='balanced')\n",
        "forest = RandomForestClassifier(class_weight='balanced')\n",
        "svc = SVC(class_weight='balanced')\n",
        "svc_lin = SVC(class_weight='balanced', kernel='linear')\n",
        "knn = KNeighborsClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "CP31B3ifMDWB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "#This is using option 1 above - all data left in, no imputation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jsX7awULMDWE",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classifier_metrics_accuracy(clf, title):\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "\n",
        "    clf.fit(X_train, y_train)\n",
        "\n",
        "    print ('%30s: %s' % ('Default score (accuracy)', clf.score(X_train, y_train)) )\n",
        "    print ('%30s: %s' % ('Cross val score', cross_val_score(clf, X_train, y_train, cv=5, scoring='accuracy').mean()) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "wPcG_SCYMDWF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def classifier_metrics_roc(clf, title):\n",
        "    y1 = label_binarize(target, classes=[0, 1, 2, 3, 4])\n",
        "    n_classes = y1.shape[1]\n",
        "    X_train, X_test, y_train, y_test = train_test_split(X, y1, test_size=.2, random_state=1)\n",
        "\n",
        "    clf1 = OneVsRestClassifier(clf).fit(X_train, y_train)\n",
        "    #clf1.fit(X_train, y_train)\n",
        "    \n",
        "    print (title)\n",
        "    for i in range(n_classes):\n",
        "\n",
        "        print ( 'AUC for class %s is %s:' % (i, (cross_val_score(clf1, X_train, y_train[:,i], cv=5, scoring='roc_auc').mean())) )\n",
        "        print ( 'Precision for class %s is %s:' % (i, (cross_val_score(clf1, X_train, y_train[:,i], cv=5, \n",
        "                                                                        scoring='precision_weighted').mean())) )\n",
        "        print ( 'Recall for class %s is %s:' % (i, (cross_val_score(clf1, X_train, y_train[:,i], cv=5, \n",
        "                                                                        scoring='recall_weighted').mean())) )\n",
        "        print ( 'F1 for class %s is %s:' % (i, (cross_val_score(clf1, X_train, y_train[:,i], cv=5, \n",
        "                                                                        scoring='f1_weighted').mean())) )\n",
        "        print ( '\\n' )\n",
        "        "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "NEz0H2_bMDWJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for clf in [logistic, treeclf, forest, svc, knn, svc_lin]:\n",
        "    title = 'Data includes missing values - no imputation' \n",
        "    print ('Metrics for %s' % clf)\n",
        "    print ('=' * 50)\n",
        "    classifier_metrics_roc(clf, title)\n",
        "    classifier_metrics_accuracy(clf, title)\n",
        "    print ('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_s7FhnkFMDWL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "model = DecisionTreeClassifier()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Sc54H0dhMDWM",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "maxdepth = []\n",
        "for i in range(1,20):\n",
        "    model = DecisionTreeClassifier(max_depth=i)\n",
        "    model.fit(X_train, y_train)\n",
        "    maxdepth.append(model.score(X_train,y_train))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t26PgUXaMDWR",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "fig = plt.figure(figsize=(6,4))\n",
        "plt.plot(range(1,20),maxdepth)\n",
        "plt.title('Overfitting of decision tree')\n",
        "plt.xlabel('max depth')\n",
        "plt.ylabel('accuracy score')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "azuiOrbGMDWT",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_ohe\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "#This is using option 2 above - ohe coding, continuous data imputed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kP2T49kzMDWV",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for clf in [logistic, treeclf, forest, svc, knn]:\n",
        "    title = 'OHE labeled, continuous data imputed' \n",
        "    print ('Metrics for %s' % clf)\n",
        "    print ('=' * 50)\n",
        "    classifier_metrics_accuracy(clf, title)\n",
        "    print ('\\n')\n",
        "    classifier_metrics_roc(clf, title)\n",
        "    print ('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "O5CKofbIMDWX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_label\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "#This is using option 3 above - label coding, continuous data imputed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ofL9FGV9MDWY",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for clf in [logistic, treeclf, forest, svc, knn]:\n",
        "    title = 'Label coded, continuous data imputed' \n",
        "    print ('Metrics for %s' % clf)\n",
        "    print ('=' * 50)\n",
        "    classifier_metrics_roc(clf, title)\n",
        "    classifier_metrics_accuracy(clf, title)\n",
        "    print ('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "4HGXK-qjMDWh",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_norm\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "#This is using option 4 above - normalized continous data, imputed discrete data"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "f5NbR6KlMDWl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for clf in [logistic, treeclf, forest, svc, knn]:\n",
        "    title = 'Normalized data' \n",
        "    print ('Metrics for %s' % clf)\n",
        "    print ('=' * 50)\n",
        "    classifier_metrics_roc(clf, title)\n",
        "    classifier_metrics_accuracy(clf, title)\n",
        "    print ('\\n')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "GZvwUvusMDWp",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import label_binarize\n",
        "from sklearn.metrics import roc_curve\n",
        "from sklearn.metrics import auc\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "import numpy as np\n",
        "from scipy import interp\n",
        "from itertools import cycle"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "bQnUqzBnMDWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "### *Moving forward with OHE labeled data and RF model*"
      ]
    },
    {
      "metadata": {
        "id": "L8tfeHwCMDWr",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 6. Hyperparameter optimizaton"
      ]
    },
    {
      "metadata": {
        "id": "82a_Ek7mMDWs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "## Tuning selected model"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kbimD9FoMDWu",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_ohe\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "royv29mLMDWw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "PARAMETERS = {'max_features':['auto','sqrt',0.2], 'max_leaf_nodes':[None,5,6,7,8,9,10,50], \n",
        "              'min_samples_leaf':[1,2,4,50], 'criterion':['gini','entropy'], 'n_estimators':[6,8,10,20,25]}\n",
        "SCORING = 'accuracy'\n",
        "\n",
        "from sklearn import grid_search\n",
        "\n",
        "#Grid Search\n",
        "model = RandomForestClassifier(class_weight='balanced')\n",
        "clf = grid_search.GridSearchCV(model, PARAMETERS, scoring=SCORING, verbose=True)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "#After completion, show the final best results and scores\n",
        "print (clf.best_estimator_)\n",
        "print (clf.best_score_)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "collapsed": true,
        "id": "tbotN5mVMDWz",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 7. Test the selected model"
      ]
    },
    {
      "metadata": {
        "id": "Flggk4rVMDWz",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "rf_model = RandomForestClassifier(bootstrap=True, class_weight='balanced',\n",
        "            criterion='gini', max_depth=None, max_features='sqrt',\n",
        "            max_leaf_nodes=50, min_samples_leaf=1, min_samples_split=2,\n",
        "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=1,\n",
        "            oob_score=False, random_state=None, verbose=0,\n",
        "            warm_start=False)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "vBE8Go5dMDW3",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_ohe\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "R98A621yMDW5",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf = rf_model.fit(X_train, y_train)\n",
        "y_eval = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "X6I911cqMDW8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.feature_importances_"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "MmMm2TvQMDW_",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "features_ohe.columns"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "kEIW4lb1MDXB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y1 = label_binarize(y_test, classes=[0, 1, 2, 3, 4])\n",
        "n_classes = y1.shape[1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "ZXII5PZ7MDXD",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "y2 = label_binarize(y_eval, classes=[0, 1, 2, 3, 4])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "khk7SO-DMDXF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "## Task 8. Assessing Model: "
      ]
    },
    {
      "metadata": {
        "id": "5smZUk6MMDXF",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Accuracy"
      ]
    },
    {
      "metadata": {
        "id": "gZROPxCkMDXH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (\"Overall model accuracy is %s\" % (accuracy_score(y_test, y_eval)) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "t_V0pf1AMDXJ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(n_classes):\n",
        "    print (\"Class %s\" % i )\n",
        "    print (accuracy_score(y1[:, i], y2[:, i]) )\n",
        "    print ('\\n' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "o9PszNKqMDXQ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### Classification Report"
      ]
    },
    {
      "metadata": {
        "id": "8pI5BJvuMDXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Y8ZT45xLMDXS",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(n_classes):\n",
        "    print (\"Class %s\" % i )\n",
        "    print (classification_report(y1[:, i], y2[:, i], labels=[1, 0]) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "qSxLH-GEMDXU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "print (f1_score(y_test, y_eval, average=None) )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eCsrF4lRMDXX",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "f1_test = [0.76470588, 0.11764706, 0.34042553, 0.4, 0.13333333]\n",
        "f1_train = [.7745, .7101, .7842, .7956, .9206]\n",
        "y = [0, .2, .4, .6, .8]\n",
        "\n",
        "fig = plt.figure(figsize=(8,6))\n",
        "ax = fig.add_subplot(111)\n",
        "\n",
        "plt.scatter(y, f1_test, color='red', label='Test')\n",
        "plt.scatter(y, f1_train, color='green', label='Train')\n",
        "classes=[0, 0, 1, 2, 3, 4]\n",
        "xTickMarks = ['Class '+ str(i) for i in classes]\n",
        "xtickNames = ax.set_xticklabels(xTickMarks, fontsize=8)\n",
        "plt.title('F1 score for training and test data')\n",
        "plt.ylabel('F1 score')\n",
        "plt.legend(loc='lower left')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "DOH_q8qdMDXZ",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "#### ROC"
      ]
    },
    {
      "metadata": {
        "id": "efZ7KHD1MDXZ",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "for i in range(n_classes):\n",
        "    print (\"Class %s\" % i )\n",
        "    print (roc_auc_score(y1[:,i], y2[:,i], average='weighted') )\n",
        "    print ('\\n' )"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "FFgkrEQDMDXb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "###### Confusion matrix"
      ]
    },
    {
      "metadata": {
        "id": "zjAvg8RsMDXb",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values, counts = np.unique(y_eval, return_counts=True)\n",
        "print (values)\n",
        "print (counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "YGpV_p1RMDXg",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "values, counts = np.unique(y_test, return_counts=True)\n",
        "print (values)\n",
        "print (counts)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "nm4LkVk4MDXj",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "V6w4h2QKMDXl",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "X = features_ohe\n",
        "y = target\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=1)\n",
        "#This is using option 2 above - ohe coding, continuous data imputed"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jO6rv8ttMDXo",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "conf_forest = confusion_matrix(y_test, y_eval)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "L4aTpu7cMDXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import itertools\n",
        "\n",
        "def plot_confusion_matrix(cm, classes,\n",
        "                          normalize=False,\n",
        "                          title='Confusion matrix',\n",
        "                          cmap=plt.cm.Blues):\n",
        "    \"\"\"\n",
        "    This function prints and plots the confusion matrix. \"\"\"\n",
        "    \n",
        "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
        "    plt.title(title)\n",
        "    plt.colorbar()\n",
        "    tick_marks = np.arange(len(classes))\n",
        "    plt.xticks(tick_marks, classes, rotation=45)\n",
        "    plt.yticks(tick_marks, classes)\n",
        "\n",
        "    thresh = cm.max() / 2.\n",
        "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
        "        plt.text(j, i, cm[i, j],\n",
        "                 horizontalalignment=\"center\",\n",
        "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.ylabel('True label')\n",
        "    plt.xlabel('Predicted label')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "zNYMpsXZMDXs",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "plot_confusion_matrix(conf_forest, classes=[0, 1, 2, 3, 4], title = 'Confusion matrix-Logistic Regression')\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}